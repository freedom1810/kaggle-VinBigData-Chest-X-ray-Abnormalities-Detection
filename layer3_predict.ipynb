{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dried-attachment",
   "metadata": {},
   "source": [
    "# load json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "becoming-variation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from  tqdm import tqdm\n",
    "\n",
    "BLUE=(255, 0, 0)\n",
    "GREEN = (0, 255, 0)\n",
    "RED = (0, 0, 255)\n",
    "YELLOW = (0, 255, 255)\n",
    "PINK = (255, 0, 255)\n",
    "BLACK = (0, 0, 0)\n",
    "ORANGE = (0, 127, 255)\n",
    "CUSTOM = (255,170,170)\n",
    "COLOR_CLASS = {0: BLUE, 1:GREEN, 2:RED, 3:YELLOW, 4:PINK, 5:BLACK, 6:ORANGE, 7:CUSTOM}\n",
    "\n",
    "# def bb_intersection_over_union(boxA, boxB):\n",
    "#     xA = max(boxA[0], boxB[0])\n",
    "#     yA = max(boxA[1], boxB[1])\n",
    "#     xB = min(boxA[2], boxB[2])\n",
    "#     yB = min(boxA[3], boxB[3])\n",
    "#     interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "\n",
    "#     boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "#     boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "\n",
    "#     iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "#     return iou\n",
    "\n",
    "def cocoToAbsoluteBox(cocoBox):\n",
    "    #xywh -> xyxy\n",
    "    return [cocoBox[0], cocoBox[1], cocoBox[0]+cocoBox[2], cocoBox[1]+cocoBox[3]]\n",
    "\n",
    "\n",
    "# matplotlib \n",
    "def plot(key, list_bbox_):\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "    plt.hist(list_bbox_[key], color = 'blue', edgecolor = 'black',\n",
    "            bins = int(len(set(list_bbox_[key]))))\n",
    "\n",
    "    # Add labels\n",
    "    plt.title('Histogram of {}'.format(key))\n",
    "    plt.xlabel(key)\n",
    "    plt.ylabel('count')\n",
    "#     plt.savefig(\"d/{}_distribution.png\".format(key))\n",
    "\n",
    "\n",
    "def bb_intersection_over_union(bb1, bb2):\n",
    "    \"\"\"\n",
    "    Calculate the Intersection over Union (IoU) of two bounding boxes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bb1 : dict\n",
    "        Keys: {'x1', 'x2', 'y1', 'y2'}\n",
    "        The (x1, y1) position is at the top left corner,\n",
    "        the (x2, y2) position is at the bottom right corner\n",
    "    bb2 : dict\n",
    "        Keys: {'x1', 'x2', 'y1', 'y2'}\n",
    "        The (x, y) position is at the top left corner,\n",
    "        the (x2, y2) position is at the bottom right corner\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        in [0, 1]\n",
    "    \"\"\"\n",
    "    bb1 = {'x1':bb1[0], 'x2':bb1[2], 'y1':bb1[1], 'y2':bb1[3]}\n",
    "    bb2 = {'x1':bb2[0], 'x2':bb2[2], 'y1':bb2[1], 'y2':bb2[3]}\n",
    "    assert bb1['x1'] < bb1['x2']\n",
    "    assert bb1['y1'] < bb1['y2']\n",
    "    assert bb2['x1'] < bb2['x2']\n",
    "    assert bb2['y1'] < bb2['y2']\n",
    "\n",
    "    # determine the coordinates of the intersection rectangle\n",
    "    x_left = max(bb1['x1'], bb2['x1'])\n",
    "    y_top = max(bb1['y1'], bb2['y1'])\n",
    "    x_right = min(bb1['x2'], bb2['x2'])\n",
    "    y_bottom = min(bb1['y2'], bb2['y2'])\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "\n",
    "    # The intersection of two axis-aligned bounding boxes is always an\n",
    "    # axis-aligned bounding box\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    # compute the area of both AABBs\n",
    "    bb1_area = (bb1['x2'] - bb1['x1']) * (bb1['y2'] - bb1['y1'])\n",
    "    bb2_area = (bb2['x2'] - bb2['x1']) * (bb2['y2'] - bb2['y1'])\n",
    "\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n",
    "    assert iou >= 0.0\n",
    "    assert iou <= 1.0\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-bankruptcy",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "improving-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations import *\n",
    "import torch\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torchcontrib.optim import SWA\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import math\n",
    "from torch.nn import BCELoss\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import gc\n",
    "\n",
    "from layer_3_net.nets import *\n",
    "\n",
    "model_params = {\n",
    "    'model_name': 'tf_efficientnet_b4_ns',\n",
    "    'pretrained': True,\n",
    "    # 'model_name': 'seresnext50_32x4d',\n",
    "    #'model_name': 'ViT-B_32',\n",
    "    #'model_name': 'vit_base_patch32_384',\n",
    "    'img_size': [256, 256],\n",
    "    'num_classes': 15,\n",
    "    'ds': False,\n",
    "    'ds_blocks': [10, 15],\n",
    "    'special_augment_prob': 1.,\n",
    "    'EMA': 1,\n",
    "    'EMA_model': ''\n",
    "    \n",
    "}\n",
    "\n",
    "training_params = {\n",
    "    'training_batch_size':120,\n",
    "    'num_workers': 16,\n",
    "    'device': torch.device(\"cuda:0\"),\n",
    "    'device_ids': [0, 1],\n",
    "    'start_epoch': 1,\n",
    "    'num_epoch': 50,\n",
    "    'warm_up': 5,\n",
    "    'TTA_time': 5\n",
    "}\n",
    "\n",
    "def load_checkpoint(path, model):\n",
    "    ckpt = torch.load(path)\n",
    "    x = list(model.state_dict().keys())\n",
    "    y = ckpt['model_state_dict']\n",
    "    from collections import OrderedDict\n",
    "    new_state_dict = OrderedDict()\n",
    "    for i, w in enumerate(y.items()):\n",
    "        k, v = w\n",
    "        name = x[i] # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "    model.load_state_dict(new_state_dict)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    \n",
    "eval_transform = Compose([\n",
    "        # Resize(model_params['img_size'][0], model_params['img_size'][1], cv2.INTER_AREA),\n",
    "        # HorizontalFlip(p=0.5),\n",
    "        # A.GaussNoise(var_limit=(150.0, 200.0), mean=0, p=0.5),\n",
    "        # A.RandomGamma(gamma_limit=(120, 120), p=0.5),\n",
    "        # A.RandomBrightnessContrast(contrast_limit=0, brightness_limit=0.2, brightness_by_max=True, p=0.5),\n",
    "        # A.Rotate(limit=10, p=0.5),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mobile-headquarters",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/hana/sonnh/kaggle-vin/final_layer3/tf_efficientnet_b4_ns_fold-2_epoch-11-1223.pt', '/home/hana/sonnh/kaggle-vin/final_layer3/tf_efficientnet_b4_ns_fold-4_epoch-11-1248.pt', '/home/hana/sonnh/kaggle-vin/final_layer3/tf_efficientnet_b4_ns_fold-5_epoch-8-2985.pt', '/home/hana/sonnh/kaggle-vin/final_layer3/tf_efficientnet_b4_ns_fold-3_epoch-8-1223.pt', '/home/hana/sonnh/kaggle-vin/final_layer3/tf_efficientnet_b4_ns_fold-1_epoch-11-630.pt']\n"
     ]
    }
   ],
   "source": [
    "path_wildcard = os.path.join('/home/hana/sonnh/kaggle-vin/final_layer3', \"*.pt\")\n",
    "ens_dir = glob.glob(path_wildcard)\n",
    "print(ens_dir)\n",
    "list_layer3_model = []\n",
    "for path in ens_dir:\n",
    "    layer3_model = EfficientNetB3DSPlus(model_params).to(torch.device(\"cpu\"),)\n",
    "    layer3_model = load_checkpoint( path, layer3_model)\n",
    "    layer3_model = layer3_model.to(training_params['device'])\n",
    "    layer3_model = nn.DataParallel(layer3_model, device_ids=[0,1])\n",
    "    layer3_model.eval()\n",
    "    list_layer3_model.append(layer3_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-paragraph",
   "metadata": {},
   "source": [
    "# load json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "global-lambda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_id': '785140281117595d1818b8133d43d3bc.dicom',\n",
       " 'category_id': 3,\n",
       " 'bbox': [1823.547, 872.074, 716.453, 448.609],\n",
       " 'score': 0.03162,\n",
       " 'conf': [8.696317672729492e-05,\n",
       "  5.918741226196289e-05,\n",
       "  6.699562072753906e-05,\n",
       "  0.0316162109375,\n",
       "  5.120038986206055e-05,\n",
       "  0.00011646747589111328,\n",
       "  4.965066909790039e-05,\n",
       "  6.568431854248047e-05,\n",
       "  4.309415817260742e-05,\n",
       "  0.00017523765563964844,\n",
       "  0.0003440380096435547,\n",
       "  0.00011515617370605469,\n",
       "  4.589557647705078e-05,\n",
       "  5.936622619628906e-05]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold = 1\n",
    "json_path = '/home/hana/sonnh/kaggle-vin/final/1920_pretrain_train_all/runs_test/fold1.json'\n",
    "data = json.load(open(json_path, 'r'))\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "medieval-bunny",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_layer_3 = {}\n",
    "for predict_anno in data:\n",
    "    image_id = predict_anno['image_id']\n",
    "    if image_id not in data_for_layer_3:\n",
    "        data_for_layer_3[image_id] = []\n",
    "    data_for_layer_3[image_id].append(predict_anno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "powered-patrol",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_for_layer_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conditional-amplifier",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "moving-moses",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(image, size):\n",
    "\n",
    "    h,w, _ = image.shape\n",
    "\n",
    "\n",
    "    BLUE = [0.5,0.5,0.5]\n",
    "\n",
    "    if h > w:\n",
    "        r = size/h\n",
    "        new_h = size\n",
    "        new_w = int(w * r)\n",
    "        if new_w % 2==1:\n",
    "            new_w += 1\n",
    "        image = cv2.resize(image, (new_w, new_h))\n",
    "        image = cv2.copyMakeBorder( image, 0,0 ,(size - new_w)//2,(size - new_w)//2, cv2.BORDER_CONSTANT, value=BLUE)\n",
    "    else:\n",
    "        r = size/w\n",
    "        new_w = size\n",
    "        new_h = int(h * r)\n",
    "        if new_h % 2==1:\n",
    "            new_h += 1\n",
    "\n",
    "        image = cv2.resize(image, (new_w, new_h))\n",
    "\n",
    "        image = cv2.copyMakeBorder( image, (size - new_h)//2,(size - new_h)//2 ,0,0, cv2.BORDER_CONSTANT, value=BLUE)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "prompt-audio",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [23:13<00:00,  2.15it/s]\n"
     ]
    }
   ],
   "source": [
    "for image_id in tqdm(list(data_for_layer_3.keys())):\n",
    "    black_list = []\n",
    "    list_small_image = []\n",
    "    list_bbox = []\n",
    "    \n",
    "    #eval\n",
    "#     img_path_wildcard = os.path.join('dataset/fold2/images/val_all', \"{}*\".format(image_id))\n",
    "#     img_paths = glob.glob(img_path_wildcard)\n",
    "#     image_ori = cv2.imread(img_paths[0])\n",
    "    \n",
    "    #test\n",
    "    image_ori = cv2.imread('/home/hana/sonnh/kaggle-vin/dataset/images_only/test/{}.dicom.png'.format(image_id[:-6]))\n",
    "\n",
    "    \n",
    "    \n",
    "#     print('dataset/fold1/images/val_all/{}.jpg'.format(image_id))\n",
    "    width, height, _ = image_ori.shape\n",
    "    out_conf_i = []\n",
    "    yolo_label_final = []\n",
    "    for i, predict_anno in enumerate(data_for_layer_3[image_id]):\n",
    "        out_conf_i.append(predict_anno['conf'])\n",
    "        xmin, ymin, w, h = predict_anno['bbox']\n",
    "        \n",
    "        yolo_label = [0]*14\n",
    "        yolo_label[predict_anno['category_id']] = 0\n",
    "        yolo_label_final.append(yolo_label)\n",
    "        \n",
    "        if w < 10 or h < 10:\n",
    "            black_list.append(i)\n",
    "            xmin, ymin, xmax, ymax = 1,1,2,2\n",
    "        else:\n",
    "            xmin = int(xmin)\n",
    "            ymin = int(ymin)\n",
    "            xmax = xmin + int(w)\n",
    "            ymax = ymin + int(h)\n",
    "            \n",
    "            \n",
    "        small_image = image_ori[ymin:ymax, xmin:xmax]\n",
    "        small_image = resize(small_image, 256)\n",
    "        small_image = eval_transform(image=small_image)[\"image\"].unsqueeze(0)\n",
    "        list_small_image.append(small_image)\n",
    "        \n",
    "            \n",
    "        list_bbox.append([xmin/width, ymin/height, xmax/width, ymax/height])\n",
    "    \n",
    "    list_small_image  = torch.cat(list_small_image, 0).to(training_params['device'])\n",
    "    list_bbox = torch.tensor(list_bbox).to(training_params['device'])\n",
    "    out_conf_i = torch.tensor(out_conf_i).to(training_params['device'])\n",
    "    yolo_label_final = torch.tensor(yolo_label_final).to(training_params['device'])\n",
    "    out_conf_final = torch.cat((yolo_label_final, out_conf_i, list_bbox), 1)\n",
    "    \n",
    "    layer3_predict_final = None\n",
    "    \n",
    "    for layer3_model in list_layer3_model:\n",
    "        batch_index = 0\n",
    "        bs = 240\n",
    "        with torch.no_grad():\n",
    "            layer3_predict_ = None\n",
    "            while batch_index + bs < len(list_small_image):\n",
    "\n",
    "                layer3_predict, _ = layer3_model(list_small_image[batch_index: batch_index + bs], \n",
    "                                                    out_conf_final[batch_index: batch_index + bs])\n",
    "                batch_index += bs\n",
    "                if layer3_predict_ is None:\n",
    "                    layer3_predict_ = layer3_predict.detach().cpu()\n",
    "                else:\n",
    "                    layer3_predict_ = torch.cat([layer3_predict_, layer3_predict.detach().cpu()], 0)\n",
    "\n",
    "\n",
    "            if batch_index < len(list_small_image):\n",
    "                layer3_predict, _ = layer3_model(list_small_image[batch_index:], \n",
    "                                                    out_conf_final[batch_index:])\n",
    "\n",
    "                if layer3_predict_ is None:\n",
    "                    layer3_predict_ = layer3_predict.detach().cpu()\n",
    "                else:\n",
    "                    layer3_predict_ = torch.cat([layer3_predict_, layer3_predict.detach().cpu()], 0)\n",
    "\n",
    "        layer3_predict = layer3_predict_\n",
    "        layer3_predict = layer3_predict.squeeze().detach().cpu().numpy()\n",
    "        layer3_predict = np.atleast_1d(layer3_predict)\n",
    "        layer3_predict = sigmoid(layer3_predict)\n",
    "        \n",
    "#         print(layer3_predict[:5])\n",
    "        if layer3_predict_final is None :\n",
    "            layer3_predict_final = layer3_predict\n",
    "        else:\n",
    "            layer3_predict_final += layer3_predict\n",
    "    \n",
    "    layer3_predict = layer3_predict_final/5\n",
    "    \n",
    "    for layer_3_i in range(len(layer3_predict)):\n",
    "        if np.argmax(layer3_predict[layer_3_i]) == 14  and layer3_predict[layer_3_i][-1] >= 0.95:\n",
    "            black_list.append(layer_3_i)\n",
    "\n",
    "    for black_list_i in black_list:\n",
    "        data_for_layer_3[image_id][black_list_i]['score'] = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-operations",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "miniature-pursuit",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "critical-flashing",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10736"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_json = []\n",
    "for image_id in data_for_layer_3:\n",
    "    for anno in data_for_layer_3[image_id]:\n",
    "        data_json.append(copy.deepcopy(anno))\n",
    "            \n",
    "c= 0\n",
    "for anno in data_json:\n",
    "    if anno['score'] == 0:\n",
    "        c += 1\n",
    "c//3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "thorough-venue",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fold = 1\n",
    "json_path = '/home/hana/sonnh/kaggle-vin/final/1920_pretrain_train_all/layer3_predict_test/fold1.json'\n",
    "json.dump(data_json, open(json_path, 'w'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-relief",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "prospective-stomach",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "convinced-documentation",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_json = []\n",
    "for image_id in data_for_layer_3:\n",
    "    img_path_wildcard = os.path.join('dataset/fold2/images/val_all', \"{}*\".format(image_id))\n",
    "    img_paths = glob.glob(img_path_wildcard)\n",
    "    \n",
    "    for anno in data_for_layer_3[image_id]:\n",
    "        for img_path in img_paths:\n",
    "            anno['image_id'] = img_path.split('/')[4].split('_')[0]\n",
    "            \n",
    "            data_json.append(copy.deepcopy(anno))\n",
    "            \n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "broadband-sudan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10267"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c= 0\n",
    "for anno in data_json:\n",
    "    if anno['score'] == 0:\n",
    "        c += 1\n",
    "c//3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "junior-columbia",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fold = 2\n",
    "epoch = 15\n",
    "iter_ = '3_3'\n",
    "\n",
    "json_path = '/home/hana/sonnh/kaggle-vin/final/1920_pretrain_train_all/layer3_predict/fold{}_{}_{}.json'.format(fold, epoch, iter_)\n",
    "json.dump(data_json, open(json_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-burlington",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
